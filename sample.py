import argparse
import os
import json

import numpy as np

from model import build_model, load_weights

from keras.models import Sequential, load_model
from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding
from music21 import instrument, note, stream, chord

DATA_DIR = './data'
MODEL_DIR = './model'
OUTPUT_DIR = './output'

def build_sample_model(vocab_size):
    model = Sequential()
    model.add(Embedding(vocab_size, 512, batch_input_shape=(1, 1)))
    for i in range(3):
        model.add(LSTM(256, return_sequences=(i != 2), stateful=True))
        model.add(Dropout(0.2))

    model.add(Dense(vocab_size))
    model.add(Activation('softmax'))
    return model

def char_idx_char_mappings():
    with open(os.path.join(DATA_DIR, 'char_to_idx.json')) as f:
        char_to_idx = json.load(f)
    idx_to_char = { i: ch for (ch, i) in char_to_idx.items() }
    vocab_size = len(char_to_idx)
    return vocab_size,idx_to_char,char_to_idx

def sample(epoch, header, num_chars,vocab_size,idx_to_char,char_to_idx):
    prediction = []
    

    model = build_sample_model(vocab_size)
    load_weights(epoch, model)
    model.save(os.path.join(MODEL_DIR, 'model.{}.h5'.format(epoch)))

    sampled = [char_to_idx[c] for c in header]
    print('\n')
    print('*' * 100)
    for i in range(num_chars):
        batch = np.zeros((1, 1))
        if sampled:
            batch[0, 0] = sampled[-1]
        else:
            batch[0, 0] = np.random.randint(vocab_size)
        result = model.predict_on_batch(batch).ravel()
        sample = np.random.choice(range(vocab_size), p=result)
        sampled.append(sample)

    
    print('Model with epoch number : ' ,epoch)
    print('Generated notes : \n')
    for c in sampled:
        #print(c,end=',')
        prediction.append(idx_to_char[c])
    return prediction

def generateMidiFile(prediction_output,modelNo):
    
    """ convert the output from the prediction to notes and create a midi file
            from the notes """
    offset = 0
    output_notes = []

    # create note and chord objects based on the values generated by the model
    for pattern in prediction_output:
        # pattern is a chord
        if ('.' in pattern) or pattern.isdigit():
            notes_in_chord = pattern.split('.')
            notes = []
            for current_note in notes_in_chord:
                new_note = note.Note(int(current_note))
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)
            new_chord = chord.Chord(notes)
            new_chord.offset = offset
            output_notes.append(new_chord)
        # pattern is a note
        else:
            new_note = note.Note(pattern)
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)

        # increase offset each iteration so that notes do not stack
        offset += 0.5
    print('output_notes: \n' ,output_notes)
    midi_stream = stream.Stream(output_notes)
    outputFileName= OUTPUT_DIR+'/output_modelEpoch_No_'+str(modelNo)+'.mid'
    midi_stream.write('midi', fp=outputFileName)

def predictModel(numChars):
    vocab_size,idx_to_char,char_to_idx = char_idx_char_mappings()
    modelWeights_epoch = [20,40,60,80,100]
    for epochs in modelWeights_epoch:
        prediction = sample(epochs,'',numChars,vocab_size,idx_to_char,char_to_idx)
        generateMidiFile(prediction , epochs)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Train the model on some text.')
    parser.add_argument('--chars', type=int, default=100, help='number of epochs to train for')
    args = parser.parse_args()
    OUTPUT_DIR = OUTPUT_DIR+'/Chars_'+str(args.chars)

    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
	
    predictModel(args.chars)